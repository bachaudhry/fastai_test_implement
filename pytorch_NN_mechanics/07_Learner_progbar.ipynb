{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Rid of the `Runner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_09 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On closer inspection, the `Runner` is not essential, especially when `Learner` already has everything it needs in its state. Thus we will implement everything inside it, while removing the need for another object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Imagenette data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
    "bs=64\n",
    "\n",
    "img_list = ImageList.from_files(path, tfms=tfms)\n",
    "split = SplitData.split_by_func(img_list, partial(grandparent_splitter,\n",
    "                                                  valid_name='val'))\n",
    "lab_list = label_by_func(split, parent_labeler, proc_y=CategoryProcessor())\n",
    "data = lab_list.to_databunch(bs, c_in=3, c_out=10, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [partial(AvgStatsCallback, accuracy),\n",
    "            CudaCallback,\n",
    "            partial(BatchTransformXCallback, norm_imagenette)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [32]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the Learner\n",
    "def param_getter(m): return m.parameters()\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, data, loss_func, opt_func=sgd_opt, lr=1e-2,\n",
    "                splitter=param_getter, cbs=None, cb_funcs=None):\n",
    "        self.model, self.data, self.loss_func, self.opt_func, self.lr, self.splitter = model, data, loss_func, opt_func, lr, splitter\n",
    "        self.in_train, self.logger, self.opt = False, print, None\n",
    "        \n",
    "        # Avoid the need for set_runner\n",
    "        self.cbs = []\n",
    "        self.add_cb(TrainEvalCallback())\n",
    "        self.add_cbs(cbs)\n",
    "        self.add_cbs(cbf() for cbf in listify(cb_funcs))\n",
    "        \n",
    "    def add_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.add_cb(cb)\n",
    "            \n",
    "    def add_cb(self, cb):\n",
    "        cb.set_runne(self)\n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "    \n",
    "    def remove_cbs(self, cbs):\n",
    "        for cb in listify(cbs): self.cbs.remove(cb)\n",
    "            \n",
    "    def one_batch(self, i, xb, yb):\n",
    "        try:\n",
    "            self.iter = i\n",
    "            self.xb, self.yb = xb, yb;                      self('begin_batch')\n",
    "            self.pred = self.model(self.xb);                self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb); self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward();                           self('after_backward')\n",
    "            self.opt.step();                                self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException:                        self('after_cancel_batch')\n",
    "        finally:                                            self('after_batch')\n",
    "            \n",
    "    def all_batches(self):\n",
    "        self.iters = len(self.dl)\n",
    "        try:\n",
    "            for i, (xb, yb) in enumerate(self.dl): self.one_batch(i, xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "            \n",
    "    def do_begin_fit(self, epochs):\n",
    "        self.epochs, self.loss = epochs, tensor(0.)\n",
    "        self('begin_fit')\n",
    "        \n",
    "    def do_begin_epoch(self, epoch):\n",
    "        self.epoch, self.dl = epoch, self.data, train_dl\n",
    "        return self('begin_epoch')\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
